{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from helpers import *\n",
    "from NLP import *\n",
    "from SentenceSplitterML import *\n",
    "from TokenizerML import *\n",
    "from lexicons import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rule-based Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can't find Mr. Nobody N. in New York City. Since 22/11/1996, \n",
      "the only way is at mr_nobody@gmail.com (or at his website: www.mr_nobody.com).\n",
      "['You', \"can't\", 'find', 'Mr.', 'Nobody', 'N.', 'in', 'New', 'York', 'City.', 'Since', '22/11/1996,', 'the', 'only', 'way', 'is', 'at', 'mr_nobody@gmail.com', '(or', 'at', 'his', 'website:', 'www.mr_nobody.com).']\n",
      "['You', \"can't\", 'find', 'Mr.', 'Nobody', 'N.', 'in', 'New', 'York', 'City', '.', 'Since', '22/11/1996', ',', 'the', 'only', 'way', 'is', 'at', 'mr_nobody@gmail.com', '(', 'or', 'at', 'his', 'website', ':', 'www.mr_nobody.com', '.)']\n",
      "['you', 'cannot', 'find', 'mr.', 'nobody', 'n.', 'in', 'new york city', 'since', '22/11/1996', 'the', 'only', 'way', 'is', 'at', 'mr_nobody@gmail.com', 'or', 'at', 'his', 'website', 'www.mr_nobody.com']\n",
      "['you', 'cannot', 'find', 'mr.', 'nobodi', 'n.', 'in', 'new york c', 'sinc', '22/11/1996', 'the', 'onli', 'wai', 'is', 'at', 'mr_nobody@gmail.com', 'or', 'at', 'hi', 'websit', 'www.mr_nobody.com']\n",
      "['cannot', 'find', 'mr.', 'nobody', 'n.', 'new york city', 'since', '22/11/1996', 'way', 'mr_nobody@gmail.com', 'website', 'www.mr_nobody.com']\n",
      "['22/11/1996', 'at', 'cannot', 'find', 'hi', 'in', 'is', 'mr.', 'mr_nobody@gmail.com', 'n.', 'new york c', 'nobodi', 'onli', 'or', 'sinc', 'the', 'wai', 'websit', 'www.mr_nobody.com', 'you']\n"
     ]
    }
   ],
   "source": [
    "name = 'test_t'\n",
    "text = get_text(name)\n",
    "tokenizer = NLP(text)\n",
    "tokenizer.tokenize()\n",
    "print(tokenizer.text)\n",
    "print(tokenizer.rough_tokens)\n",
    "print(tokenizer.dirty_tokens)\n",
    "print(tokenizer.tokens)\n",
    "print(tokenizer.stemmed_tokens)\n",
    "print(tokenizer.pruned_tokens)\n",
    "tokenizer.make_vocabulary(token_type = \"stemmed\")\n",
    "print(tokenizer.vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rule-based sentence splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It would be unfair to demand that people cease pirating files\n",
      " when those same people aren't paid for their participation in\n",
      "  very lucrative network schemes networking. Ordinary people are relentlessly\n",
      "   spied on, and not compensated for information taken from them. \n",
      "While I'd like to see everyone eventually pay for music and the like, \n",
      "I'd not ask for it until there's reciprocity. Don't liking her.\n",
      "don't,be.:example@gmail.com Multiplications\n",
      "Mr. Winston Churcil is not a good person. But 10.8$ is enoguht for us.\n",
      "I drove 50 m.p.h. and got a speeding ticket.\n",
      "[\"It would be unfair to demand that people cease pirating files when those same people aren't paid for their participation in very lucrative network schemes networking.\"]\n",
      "['Ordinary people are relentlessly spied on, and not compensated for information taken from them.']\n",
      "[\"While I'd like to see everyone eventually pay for music and the like, I'd not ask for it until there's reciprocity.\"]\n",
      "[\"Don't liking her.\"]\n",
      "[\"don't,be.:example@gmail.com Multiplications Mr. Winston Churcil is not a good person.\"]\n",
      "['But 10.8$ is enoguht for us.']\n",
      "['I drove 50 m.p.h. and got a speeding ticket.']\n"
     ]
    }
   ],
   "source": [
    "name = 'test_ss'\n",
    "text = get_text(name)\n",
    "tokenizer = NLP(text)\n",
    "tokenizer.sentence_split()\n",
    "sentences = tokenizer.sentences\n",
    "print(text)\n",
    "for sentence in sentences:\n",
    "    print([sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabularies and word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'would', 'be', 'unfair', 'to', 'demand', 'that', 'people', 'cease', 'pirating', 'files', 'when', 'those', 'same', 'people', 'are', 'not', 'paid', 'for', 'their', 'participation', 'in', 'very', 'lucrative', 'network', 'schemes', 'networking', 'ordinary', 'people', 'are', 'relentlessly', 'spied', 'on', 'and', 'not', 'compensated', 'for', 'information', 'taken', 'from', 'them', 'while', 'i', 'would', 'like', 'to', 'see', 'everyone', 'eventually', 'pay', 'for', 'music', 'and', 'the', 'like', 'i', 'would', 'not', 'ask', 'for', 'it', 'until', 'there', 'is', 'reciprocity', 'do', 'not', 'liking', 'her', 'do', 'not', 'be.', 'example@gmail.com', 'multiplications', 'mr.', 'winston', 'churcil', 'is', 'not', 'a', 'good', 'person', 'but', '10.8$', 'is', 'enoguht', 'for', 'us', 'i', 'drove', '50', 'm.p.h.', 'and', 'got', 'a', 'speeding', 'ticket']\n",
      "['10.8$', '50', 'a', 'and', 'are', 'ask', 'be', 'be.', 'but', 'cease', 'churcil', 'compensated', 'demand', 'do', 'drove', 'enoguht', 'eventually', 'everyone', 'example@gmail.com', 'files', 'for', 'from', 'good', 'got', 'her', 'i', 'in', 'information', 'is', 'it', 'like', 'liking', 'lucrative', 'm.p.h.', 'mr.', 'multiplications', 'music', 'network', 'networking', 'not', 'on', 'ordinary', 'paid', 'participation', 'pay', 'people', 'person', 'pirating', 'reciprocity', 'relentlessly', 'same', 'schemes', 'see', 'speeding', 'spied', 'taken', 'that', 'the', 'their', 'them', 'there', 'those', 'ticket', 'to', 'unfair', 'until', 'us', 'very', 'when', 'while', 'winston', 'would']\n",
      "{'not': 6, 'for': 5, 'would': 3, 'people': 3, 'and': 3, 'i': 3, 'is': 3, 'it': 2, 'to': 2, 'are': 2, 'like': 2, 'do': 2, 'a': 2, 'be': 1, 'unfair': 1, 'demand': 1, 'that': 1, 'cease': 1, 'pirating': 1, 'files': 1, 'when': 1, 'those': 1, 'same': 1, 'paid': 1, 'their': 1, 'participation': 1, 'in': 1, 'very': 1, 'lucrative': 1, 'network': 1, 'schemes': 1, 'networking': 1, 'ordinary': 1, 'relentlessly': 1, 'spied': 1, 'on': 1, 'compensated': 1, 'information': 1, 'taken': 1, 'from': 1, 'them': 1, 'while': 1, 'see': 1, 'everyone': 1, 'eventually': 1, 'pay': 1, 'music': 1, 'the': 1, 'ask': 1, 'until': 1, 'there': 1, 'reciprocity': 1, 'liking': 1, 'her': 1, 'be.': 1, 'example@gmail.com': 1, 'multiplications': 1, 'mr.': 1, 'winston': 1, 'churcil': 1, 'good': 1, 'person': 1, 'but': 1, '10.8$': 1, 'enoguht': 1, 'us': 1, 'drove': 1, '50': 1, 'm.p.h.': 1, 'got': 1, 'speeding': 1, 'ticket': 1}\n"
     ]
    }
   ],
   "source": [
    "name = 'test_ss'\n",
    "text = get_text(name)\n",
    "tokenizer = NLP(text)\n",
    "tokenizer.make_vocabulary()\n",
    "print(tokenizer.tokens)\n",
    "print(tokenizer.vocabulary)\n",
    "print(tokenizer.get_word_frequencies(token_type = \"clean\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_features in module TokenizerML:\n",
      "\n",
      "get_features(sample, index) method of TokenizerML.TokenizerML instance\n",
      "    Function for feature compilation. To see the composition of sample list\n",
      "    look at get_samples function.\n",
      "    Features:\n",
      "    F0: Is character a letter?\n",
      "    F1: Is character a number?\n",
      "    F2: Is character a whitespace?\n",
      "    F3: Is character between two alphanumeric values?\n",
      "    F4: Is character a punctuation sign?\n",
      "    F5: Is character next to a number?\n",
      "    F6: Is character @?\n",
      "    F7: Is character a punctuation sign between two alphanumeric values?\n",
      "\n",
      "None\n",
      "Y [1, 0, 0, 0, 0, 0, 0, 0] => [0]\n",
      "o [1, 0, 0, 1, 0, 0, 0, 0] => [0]\n",
      "u [1, 0, 0, 0, 0, 0, 0, 0] => [0]\n",
      "  [0, 0, 1, 1, 0, 0, 0, 0] => [1]\n",
      "c [1, 0, 0, 0, 0, 0, 0, 0] => [0]\n",
      "' [0, 0, 0, 1, 1, 0, 0, 1] => [0]\n",
      "t [1, 0, 0, 0, 0, 0, 0, 0] => [0]\n",
      "  [0, 0, 1, 1, 0, 0, 0, 0] => [1]\n",
      "f [1, 0, 0, 0, 0, 0, 0, 0] => [0]\n",
      "d [1, 0, 0, 0, 0, 0, 0, 0] => [0]\n",
      "  [0, 0, 1, 1, 0, 0, 0, 0] => [1]\n",
      "M [1, 0, 0, 0, 0, 0, 0, 0] => [0]\n",
      "r [1, 0, 0, 0, 0, 0, 0, 0] => [0]\n",
      ". [0, 0, 0, 0, 1, 0, 0, 0] => [0]\n",
      "  [0, 0, 1, 0, 0, 0, 0, 0] => [1]\n"
     ]
    }
   ],
   "source": [
    "m = TokenizerML()\n",
    "dataset = get_text('trainset_t')\n",
    "features, targets = m.make_dataset(dataset)\n",
    "print(help(m.get_features))\n",
    "for s, f, t in zip(m.stand_text[0:15], features[0:15], targets[0:15]):\n",
    "    print(s + \" \" + str(f) + \" => \" + str([t]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can't find Mr. Nobody N. in New York City. Since 22/11/1996, \n",
      "the only way is at mr_nobody@gmail.com (or at his website: www.mr_nobody.com).\n",
      "Y [1, 0, 0, 0, 0, 0, 0, 0] => [0] with p = [0.98046019 0.01953981]\n",
      "o [1, 0, 0, 1, 0, 0, 0, 0] => [0] with p = [0.98212894 0.01787106]\n",
      "u [1, 0, 0, 0, 0, 0, 0, 0] => [0] with p = [0.98046019 0.01953981]\n",
      "  [0, 0, 1, 1, 0, 0, 0, 0] => [1] with p = [0.02317899 0.97682101]\n",
      "c [1, 0, 0, 0, 0, 0, 0, 0] => [0] with p = [0.98046019 0.01953981]\n",
      "a [1, 0, 0, 1, 0, 0, 0, 0] => [0] with p = [0.98212894 0.01787106]\n",
      "n [1, 0, 0, 0, 0, 0, 0, 0] => [0] with p = [0.98046019 0.01953981]\n",
      "' [0, 0, 0, 1, 1, 0, 0, 1] => [0] with p = [0.57554159 0.42445841]\n",
      "t [1, 0, 0, 0, 0, 0, 0, 0] => [0] with p = [0.98046019 0.01953981]\n",
      "  [0, 0, 1, 1, 0, 0, 0, 0] => [1] with p = [0.02317899 0.97682101]\n",
      "f [1, 0, 0, 0, 0, 0, 0, 0] => [0] with p = [0.98046019 0.01953981]\n",
      "i [1, 0, 0, 1, 0, 0, 0, 0] => [0] with p = [0.98212894 0.01787106]\n",
      "n [1, 0, 0, 1, 0, 0, 0, 0] => [0] with p = [0.98212894 0.01787106]\n",
      "d [1, 0, 0, 0, 0, 0, 0, 0] => [0] with p = [0.98046019 0.01953981]\n",
      "  [0, 0, 1, 1, 0, 0, 0, 0] => [1] with p = [0.02317899 0.97682101]\n",
      "['You', \"can't\", 'find', 'Mr', '.', 'Nobody', 'N', '.', 'in', 'New', 'York', 'City', '.', 'Since', '22/11/1996', ',', 'the', 'only', 'way', 'is', 'at', 'mr_nobody@gmail.com', '(', 'or', 'at', 'his', 'website', ':', 'www.mr_nobody.com', ')', '.', '']\n"
     ]
    }
   ],
   "source": [
    "name = 'test_t'\n",
    "text = get_text(name)\n",
    "print(text)\n",
    "mltokenizer = TokenizerML()\n",
    "tokens, features, targets, probs = mltokenizer.tokenize_ml(text)\n",
    "for s, f, t, p in zip(mltokenizer.stand_text[0:15], features[0:15], targets, probs[0:15]):\n",
    "    print(s + \" \" + str(f) + \" => \" + str([t]) + \" with p = \" + str(p))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence splitting using Logistical Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method get_features in module SentenceSplitterML:\n",
      "\n",
      "get_features(sample_list) method of SentenceSplitterML.SentenceSplitterML instance\n",
      "    Function for feature compilation. To see the composition of sample list\n",
      "    look at get_samples function.\n",
      "    Features:\n",
      "    F0: Is punctuation a period?\n",
      "    F1: Is previous character lower_case?\n",
      "    F2: Is previous character upper_case?\n",
      "    F3: Is previous character number?\n",
      "    F4: Is next character letter?\n",
      "    F5: Is next character number?\n",
      "    F6: Is next character whitespace?\n",
      "    F7: Is previous token an abbreviation?\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "m = SentenceSplitterML()\n",
    "dataset = get_text('trainset_ss')\n",
    "m.make_dataset(dataset)\n",
    "print(help(m.get_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It would be unfair to demand that people cease pirating files\n",
      " when those same people aren't paid for their participation in\n",
      "  very lucrative network schemes networking. Ordinary people are relentlessly\n",
      "   spied on, and not compensated for information taken from them. \n",
      "While I'd like to see everyone eventually pay for music and the like, \n",
      "I'd not ask for it until there's reciprocity. Don't liking her.\n",
      "don't,be.:example@gmail.com Multiplications\n",
      "Mr. Winston Churcil is not a good person. But 10.8$ is enoguht for us.\n",
      "I drove 50 m.p.h. and got a speeding ticket.\n",
      "[1 1 1 1 0 0 0 1 0 1 0 0 0 0]\n",
      "[[0.29224788 0.70775212]\n",
      " [0.29224788 0.70775212]\n",
      " [0.29224788 0.70775212]\n",
      " [0.29224788 0.70775212]\n",
      " [0.82581031 0.17418969]\n",
      " [0.93637777 0.06362223]\n",
      " [0.7063189  0.2936811 ]\n",
      " [0.29224788 0.70775212]\n",
      " [0.92868398 0.07131602]\n",
      " [0.29224788 0.70775212]\n",
      " [0.93637777 0.06362223]\n",
      " [0.93637777 0.06362223]\n",
      " [0.7063189  0.2936811 ]\n",
      " [0.82581031 0.17418969]]\n",
      "[\"It would be unfair to demand that people cease pirating files when those same people aren't paid for their participation in very lucrative network schemes networking.\"]\n",
      "['Ordinary people are relentlessly spied on, and not compensated for information taken from them.']\n",
      "[\"While I'd like to see everyone eventually pay for music and the like, I'd not ask for it until there's reciprocity.\"]\n",
      "[\"Don't liking her.\"]\n",
      "[\"don't,be.:example@gmail.com Multiplications Mr. Winston Churcil is not a good person.\"]\n",
      "['But 10.8$ is enoguht for us.']\n",
      "['I drove 50 m.p.h. and got a speeding ticket.']\n"
     ]
    }
   ],
   "source": [
    "txt = get_text('test_ss')\n",
    "print(txt)\n",
    "m = SentenceSplitterML()\n",
    "sentences = m.sentence_split_ml(txt)\n",
    "for sentence in sentences:\n",
    "    print([sentence])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on random text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shepseskaf's relation to his predecessor Menkaure is not entirely certain; he might have been his son or possibly his brother. \n",
      "The identity of his mother is highly uncertain as she could have been one of Menkaure's consorts or queen Khentkaus I or Neferhetepes. \n",
      "Similarly, Shepseskaf's relation to his probable successor on the throne, Userkaf, is not known although in the absence of clear indication \n",
      "of strife at the transition between the fourth and fifth dynasties, Userkaf could well have been his son or his brother. If Shepseskaf was\n",
      " succeeded directly by Userkaf rather than by Thampthis as claimed by some historical sources, then his death marks the end of the fourth dynasty. \n",
      " The transition to the fifth dynasty seems not to have been a sharp rupture but rather a continuous process of evolution in the king's power and role \n",
      " within the Egyptian state. Around this time, some of the highest positions of power such as that of vizier which had hitherto been the prerogative \n",
      " of the royal family were opened to nobles of non-royal extraction.\n",
      "\n",
      "The only activities firmly datable to Shepseskaf's short reign are the completion of the hitherto unfinished mortuary complex of the Pyramid of \n",
      "Menkaure using mudbricks and the construction of his own tomb at South Saqqara, now known as the Mastabat al-Fir'aun. Shepseskaf's decisions to \n",
      "abandon the Giza necropolis and to build a mastaba, that is a flat-roofed rectangular structure, rather than a pyramid for himself are significant \n",
      "and continue to be debated. Some Egyptologists see these decisions as symptoms of a power-struggle between the king and the priesthood of Ra, while \n",
      "others believe purely practical considerations, possibly including a declining economy, are at fault. Alternatively, it may be that Shepseskaf intended \n",
      "his tomb to be a pyramid, but after his death it was completed as a mastaba. Possibly because of this, and the small dimensions of his tomb compared\n",
      " to those of his forebears and his short reign, Shepseskaf was the object of a relatively minor state-sponsored funerary cult that disappeared in \n",
      " the second half of the fifth dynasty. This cult was revived in the later Middle Kingdom period as a privately run lucrative cult aimed at \n",
      " guaranteeing a royal intercessor for the offerings made to their dead by members of the lower strata of society.\n",
      "['shepseskaf', 'is', 'relation', 'to', 'his', 'predecessor', 'menkaure', 'is', 'not', 'entirely', 'certain', 'he', 'might', 'have', 'been', 'his', 'son', 'or', 'possibly', 'his', 'brother', 'the', 'identity', 'of', 'his', 'mother', 'is', 'highly', 'uncertain', 'as', 'she', 'could', 'have', 'been', 'one', 'of', 'menkaure', 'is', 'consorts', 'or', 'queen', 'khentkaus', 'i or', 'neferhetepes', 'similarly', 'shepseskaf', 'is', 'relation', 'to', 'his', 'probable', 'successor', 'on', 'the', 'throne', 'userkaf', 'is', 'not', 'known', 'although', 'in', 'the', 'absence', 'of', 'clear', 'indication', 'of', 'strife', 'at', 'the', 'transition', 'between', 'the', 'fourth', 'and', 'fifth', 'dynasties', 'userkaf', 'could', 'well', 'have', 'been', 'his', 'son', 'or', 'his', 'brother', 'if', 'shepseskaf', 'was', 'succeeded', 'directly', 'by', 'userkaf', 'rather', 'than', 'by', 'thampthis', 'as', 'claimed', 'by', 'some', 'historical', 'sources', 'then', 'his', 'death', 'marks', 'the', 'end', 'of', 'the', 'fourth', 'dynasty', 'the', 'transition', 'to', 'the', 'fifth', 'dynasty', 'seems', 'not', 'to', 'have', 'been', 'a', 'sharp', 'rupture', 'but', 'rather', 'a', 'continuous', 'process', 'of', 'evolution', 'in', 'the', 'king', 'is', 'power', 'and', 'role', 'within', 'the', 'egyptian', 'state', 'around', 'this', 'time', 'some', 'of', 'the', 'highest', 'positions', 'of', 'power', 'such', 'as', 'that', 'of', 'vizier', 'which', 'had', 'hitherto', 'been', 'the', 'prerogative', 'of', 'the', 'royal', 'family', 'were', 'opened', 'to', 'nobles', 'of', 'non-royal', 'extraction', 'the', 'only', 'activities', 'firmly', 'datable', 'to', 'shepseskaf', 'is', 'short', 'reign', 'are', 'the', 'completion', 'of', 'the', 'hitherto', 'unfinished', 'mortuary', 'complex', 'of', 'the', 'pyramid', 'of', 'menkaure', 'using', 'mudbricks', 'and', 'the', 'construction', 'of', 'his', 'own', 'tomb', 'at', 'south', 'saqqara', 'now', 'known', 'as', 'the', 'mastabat', \"al-fir'aun\", 'shepseskaf', 'is', 'decisions', 'to', 'abandon', 'the', 'giza', 'necropolis', 'and', 'to', 'build', 'a', 'mastaba', 'that', 'is a', 'flat-roofed', 'rectangular', 'structure', 'rather', 'than', 'a', 'pyramid', 'for', 'himself', 'are', 'significant', 'and', 'continue', 'to', 'be', 'debated', 'some', 'egyptologists', 'see', 'these', 'decisions', 'as', 'symptoms', 'of', 'a', 'power-struggle', 'between', 'the', 'king', 'and', 'the', 'priesthood', 'of', 'ra', 'while', 'others', 'believe', 'purely', 'practical', 'considerations', 'possibly', 'including', 'a', 'declining', 'economy', 'are', 'at', 'fault', 'alternatively', 'it', 'may', 'be', 'that', 'shepseskaf', 'intended', 'his', 'tomb', 'to', 'be', 'a', 'pyramid', 'but', 'after', 'his', 'death', 'it', 'was', 'completed', 'as', 'a', 'mastaba', 'possibly', 'because', 'of', 'this', 'and', 'the', 'small', 'dimensions', 'of', 'his', 'tomb', 'compared', 'to', 'those', 'of', 'his', 'forebears', 'and', 'his', 'short', 'reign', 'shepseskaf', 'was', 'the', 'object', 'of', 'a', 'relatively', 'minor', 'state-sponsored', 'funerary', 'cult', 'that', 'disappeared', 'in', 'the', 'second', 'half', 'of', 'the', 'fifth', 'dynasty', 'this', 'cult', 'was', 'revived', 'in', 'the', 'later', 'middle', 'kingdom', 'period', 'as', 'a', 'privately', 'run', 'lucrative', 'cult', 'aimed', 'at', 'guaranteeing', 'a', 'royal', 'intercessor', 'for', 'the', 'offerings', 'made', 'to', 'their', 'dead', 'by', 'members', 'of', 'the', 'lower', 'strata', 'of', 'society']\n",
      "['shepseskaf', 'is', 'relat', 'to', 'hi', 'predecessor', 'menkaur', 'is', 'not', 'entir', 'certain', 'he', 'might', 'have', 'been', 'hi', 'son', 'or', 'possibli', 'hi', 'brother', 'the', 'ident', 'of', 'hi', 'mother', 'is', 'highli', 'uncertain', 'as', 'she', 'could', 'have', 'been', 'on', 'of', 'menkaur', 'is', 'consort', 'or', 'queen', 'khentkau', 'i or', 'neferhetep', 'similarli', 'shepseskaf', 'is', 'relat', 'to', 'hi', 'probabl', 'successor', 'on', 'the', 'throne', 'userkaf', 'is', 'not', 'known', 'although', 'in', 'the', 'absenc', 'of', 'clear', 'indic', 'of', 'strife', 'at', 'the', 'transit', 'between', 'the', 'fourth', 'and', 'fifth', 'dynasti', 'userkaf', 'could', 'well', 'have', 'been', 'hi', 'son', 'or', 'hi', 'brother', 'if', 'shepseskaf', 'wa', 'succeed', 'directli', 'by', 'userkaf', 'rather', 'than', 'by', 'thampthi', 'as', 'claim', 'by', 'some', 'histor', 'sourc', 'then', 'hi', 'death', 'mark', 'the', 'end', 'of', 'the', 'fourth', 'dynasti', 'the', 'transit', 'to', 'the', 'fifth', 'dynasti', 'seem', 'not', 'to', 'have', 'been', 'a', 'sharp', 'ruptur', 'but', 'rather', 'a', 'continu', 'process', 'of', 'evolut', 'in', 'the', 'king', 'is', 'power', 'and', 'role', 'within', 'the', 'egyptian', 'state', 'around', 'thi', 'time', 'some', 'of', 'the', 'highest', 'posit', 'of', 'power', 'such', 'as', 'that', 'of', 'vizier', 'which', 'had', 'hitherto', 'been', 'the', 'prerog', 'of', 'the', 'royal', 'famili', 'were', 'open', 'to', 'nobl', 'of', 'non-roy', 'extract', 'the', 'onli', 'activ', 'firmli', 'databl', 'to', 'shepseskaf', 'is', 'short', 'reign', 'ar', 'the', 'complet', 'of', 'the', 'hitherto', 'unfinish', 'mortuari', 'complex', 'of', 'the', 'pyramid', 'of', 'menkaur', 'us', 'mudbrick', 'and', 'the', 'construct', 'of', 'hi', 'own', 'tomb', 'at', 'south', 'saqqara', 'now', 'known', 'as', 'the', 'mastabat', \"al-fir'aun\", 'shepseskaf', 'is', 'decis', 'to', 'abandon', 'the', 'giza', 'necropoli', 'and', 'to', 'build', 'a', 'mastaba', 'that', 'is a', 'flat-roof', 'rectangular', 'structur', 'rather', 'than', 'a', 'pyramid', 'for', 'himself', 'ar', 'signific', 'and', 'continu', 'to', 'be', 'debat', 'some', 'egyptologist', 'see', 'these', 'decis', 'as', 'symptom', 'of', 'a', 'power-struggl', 'between', 'the', 'king', 'and', 'the', 'priesthood', 'of', 'ra', 'while', 'other', 'believ', 'pure', 'practic', 'consider', 'possibli', 'includ', 'a', 'declin', 'economi', 'ar', 'at', 'fault', 'altern', 'it', 'mai', 'be', 'that', 'shepseskaf', 'intend', 'hi', 'tomb', 'to', 'be', 'a', 'pyramid', 'but', 'after', 'hi', 'death', 'it', 'wa', 'complet', 'as', 'a', 'mastaba', 'possibli', 'becaus', 'of', 'thi', 'and', 'the', 'small', 'dimens', 'of', 'hi', 'tomb', 'compar', 'to', 'those', 'of', 'hi', 'forebear', 'and', 'hi', 'short', 'reign', 'shepseskaf', 'wa', 'the', 'object', 'of', 'a', 'rel', 'minor', 'state-sponsor', 'funerari', 'cult', 'that', 'disappear', 'in', 'the', 'second', 'half', 'of', 'the', 'fifth', 'dynasti', 'thi', 'cult', 'wa', 'reviv', 'in', 'the', 'later', 'middl', 'kingdom', 'period', 'as', 'a', 'privat', 'run', 'lucr', 'cult', 'aim', 'at', 'guarante', 'a', 'royal', 'intercessor', 'for', 'the', 'offer', 'made', 'to', 'their', 'dead', 'by', 'member', 'of', 'the', 'lower', 'strata', 'of', 'societi']\n",
      "[\"Shepseskaf's relation to his predecessor Menkaure is not entirely certain; he might have been his son or possibly his brother.\"]\n",
      "[\"The identity of his mother is highly uncertain as she could have been one of Menkaure's consorts or queen Khentkaus I or Neferhetepes.\"]\n",
      "[\"Similarly, Shepseskaf's relation to his probable successor on the throne, Userkaf, is not known although in the absence of clear indication of strife at the transition between the fourth and fifth dynasties, Userkaf could well have been his son or his brother.\"]\n",
      "['If Shepseskaf was succeeded directly by Userkaf rather than by Thampthis as claimed by some historical sources, then his death marks the end of the fourth dynasty.']\n",
      "[\"The transition to the fifth dynasty seems not to have been a sharp rupture but rather a continuous process of evolution in the king's power and role within the Egyptian state.\"]\n",
      "['Around this time, some of the highest positions of power such as that of vizier which had hitherto been the prerogative of the royal family were opened to nobles of non-royal extraction.']\n",
      "[\"The only activities firmly datable to Shepseskaf's short reign are the completion of the hitherto unfinished mortuary complex of the Pyramid of Menkaure using mudbricks and the construction of his own tomb at South Saqqara, now known as the Mastabat al-Fir'aun.\"]\n",
      "[\"Shepseskaf's decisions to abandon the Giza necropolis and to build a mastaba, that is a flat-roofed rectangular structure, rather than a pyramid for himself are significant and continue to be debated.\"]\n",
      "['Some Egyptologists see these decisions as symptoms of a power-struggle between the king and the priesthood of Ra, while others believe purely practical considerations, possibly including a declining economy, are at fault.']\n",
      "['Alternatively, it may be that Shepseskaf intended his tomb to be a pyramid, but after his death it was completed as a mastaba.']\n",
      "['Possibly because of this, and the small dimensions of his tomb compared to those of his forebears and his short reign, Shepseskaf was the object of a relatively minor state-sponsored funerary cult that disappeared in the second half of the fifth dynasty.']\n",
      "['This cult was revived in the later Middle Kingdom period as a privately run lucrative cult aimed at guaranteeing a royal intercessor for the offerings made to their dead by members of the lower strata of society.']\n"
     ]
    }
   ],
   "source": [
    "name = 'txt2'\n",
    "text = get_text(name)\n",
    "tokenizer = NLP(text)\n",
    "tokenizer.tokenize()\n",
    "print(tokenizer.text)\n",
    "print(tokenizer.tokens)\n",
    "print(tokenizer.stemmed_tokens)\n",
    "#print(tokenizer.stemmed_tokens)\n",
    "tokenizer.sentence_split()\n",
    "sentences = tokenizer.sentences\n",
    "for sentence in sentences:\n",
    "    print([sentence])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nlp_p1': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e14664053d37e575f017670323f8571077f235bd162d1842d904390d31d3de60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

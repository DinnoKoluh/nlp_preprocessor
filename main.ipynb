{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from funs import *\n",
    "from NLP import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['din', ',', 'no', 'e.g.', 'you']\n"
     ]
    }
   ],
   "source": [
    "ex = 'din,noe.g.you'\n",
    "t = NLP([])\n",
    "print(t.split_by_string(ex, 'e.g.', [',']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this m.p.h.\n",
      "Mr. perm.project, you will design and .?impl,,,ement a preprocessing toolkit for Turkish (Turkish\n",
      "students in the class) or English (non-Turkish students in the class). The   processing functionalities.  \n",
      "a,b,c, $45.78 \"bills?\"\n",
      "\n",
      ",,..dinno.koluh@gmail.com..?,., I'm here http://www.stanford.edu\n",
      "\n",
      "The Treebank tokenizer uses regular expressions to tokenize text as in Penn Treebank.\n",
      "This  by Robert McIntyre and available at http://www.cis.upenn.edu/~treebank/tokenizer.sed.\n",
      "God is Great! I won a lottery.\n",
      "\n",
      "\n",
      "['In', 'this', 'm.p.h.', 'Mr.', 'perm.project,', 'you', 'will', 'design', 'and', '.?impl,,,ement', 'a', 'preprocessing', 'toolkit', 'for', 'Turkish', '(Turkish', 'students', 'in', 'the', 'class)', 'or', 'English', '(non-Turkish', 'students', 'in', 'the', 'class).', 'The', 'processing', 'functionalities.', 'a,b,c,', '$45.78', '\"bills?\"', ',,..dinno.koluh@gmail.com..?,.,', \"I'm\", 'here', 'http://www.stanford.edu', 'The', 'Treebank', 'tokenizer', 'uses', 'regular', 'expressions', 'to', 'tokenize', 'text', 'as', 'in', 'Penn', 'Treebank.', 'This', 'by', 'Robert', 'McIntyre', 'and', 'available', 'at', 'http://www.cis.upenn.edu/~treebank/tokenizer.sed.', 'God', 'is', 'Great!', 'I', 'won', 'a', 'lottery.']\n",
      "['In this m.p.h. Mr. perm.project, you will design and .?impl,,,ement a preprocessing toolkit for Turkish (Turkish students in the class) or English (non-Turkish students in the class).']\n",
      "['The processing functionalities.']\n",
      "['a,b,c, $45.78 \"bills?\" ,,..dinno.koluh@gmail.com..?,., I\\'m here http://www.stanford.edu The Treebank tokenizer uses regular expressions to tokenize text as in Penn Treebank.']\n",
      "['This by Robert McIntyre and available at http://www.cis.upenn.edu/~treebank/tokenizer.sed.']\n",
      "['God is Great!']\n",
      "['I won a lottery.']\n"
     ]
    }
   ],
   "source": [
    "name = 'txt1'\n",
    "text = get_text(name)\n",
    "tokenizer = NLP(text)\n",
    "tokenizer.tokenize()\n",
    "tokenizer.sentence_split()\n",
    "print(tokenizer.text)\n",
    "print(tokenizer.rough_tokens)\n",
    "sentences = tokenizer.sentences\n",
    "for s in sentences:\n",
    "    print([s])\n",
    "#tokenizer.make_vocabulary(sorted_voc=False)\n",
    "# print(tokenizer.text)\n",
    "#print(tokenizer.rough_tokens)\n",
    "# print(tokenizer.tokens)\n",
    "# print(text)\n",
    "# voc  = tokenizer.vocabulary\n",
    "# freq = tokenizer.word_frequency\n",
    "# print(voc)\n",
    "# print(freq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset was collected and prepared by Mr. Machiaveli the CALO Project (A Cognitive Assistant that Learns and Organizes). \n",
      "It contains data from about 150 users, mostly senior management of Enron, organized into folders. \n",
      "The of about 0.5M messages. This public, and posted to the web, \n",
      "by the Federal Energy Regulatory Commission during its investigation?\n",
      "The email dataset was later purchased by Leslie Kaelbling at MIT, and problems.\n",
      " A number of folks at SRI, notably Melinda Gervasio, worked problems, and it is thanks to them (not me)\n",
      "  that the dataset is available. The include attachments, and been deleted \n",
      "  \"as part of a redaction effort due to requests from affected employees\". Invalid of the form user@enron.com.,' whenever\n",
      "   possible ..(i.e., recipient is specified in some parse-able format like \n",
      "  \"Doe, John\" or \"Mary K. Smith\") and to ,no_address@enron.com:koluh_dinno@gmail.com; when no recipient was specified...\n",
      "I get a each week, which I am unable to answer, $45,000,055\n",
      "mostly that I just don't know about. If you ask me a question and I don't answer, \n",
      "please 'don't',don't.mindme  ' feel slighted.  . dino!==? hello,Mr.,\n",
      "\n",
      "\n",
      "\n",
      "['This', 'dataset', 'was', 'collected', 'and', 'prepared', 'by', 'Mr.', 'Machiaveli', 'the', 'CALO', 'Project', '(A', 'Cognitive', 'Assistant', 'that', 'Learns', 'and', 'Organizes).', 'It', 'contains', 'data', 'from', 'about', '150', 'users,', 'mostly', 'senior', 'management', 'of', 'Enron,', 'organized', 'into', 'folders.', 'The', 'of', 'about', '0.5M', 'messages.', 'This', 'public,', 'and', 'posted', 'to', 'the', 'web,', 'by', 'the', 'Federal', 'Energy', 'Regulatory', 'Commission', 'during', 'its', 'investigation?', 'The', 'email', 'dataset', 'was', 'later', 'purchased', 'by', 'Leslie', 'Kaelbling', 'at', 'MIT,', 'and', 'problems.', 'A', 'number', 'of', 'folks', 'at', 'SRI,', 'notably', 'Melinda', 'Gervasio,', 'worked', 'problems,', 'and', 'it', 'is', 'thanks', 'to', 'them', '(not', 'me)', 'that', 'the', 'dataset', 'is', 'available.', 'The', 'include', 'attachments,', 'and', 'been', 'deleted', '\"as', 'part', 'of', 'a', 'redaction', 'effort', 'due', 'to', 'requests', 'from', 'affected', 'employees\".', 'Invalid', 'of', 'the', 'form', \"user@enron.com.,'\", 'whenever', 'possible', '..(i.e.,', 'recipient', 'is', 'specified', 'in', 'some', 'parse-able', 'format', 'like', '\"Doe,', 'John\"', 'or', '\"Mary', 'K.', 'Smith\")', 'and', 'to', ',no_address@enron.com:koluh_dinno@gmail.com;', 'when', 'no', 'recipient', 'was', 'specified...', 'I', 'get', 'a', 'each', 'week,', 'which', 'I', 'am', 'unable', 'to', 'answer,', '$45,000,055', 'mostly', 'that', 'I', 'just', \"don't\", 'know', 'about.', 'If', 'you', 'ask', 'me', 'a', 'question', 'and', 'I', \"don't\", 'answer,', 'please', \"'don't',don't.mindme\", \"'\", 'feel', 'slighted.', '.', 'dino!==?', 'hello,Mr.,']\n",
      "['This', 'dataset', 'was', 'collected', 'and', 'prepared', 'by', 'Mr.', 'Machiaveli', 'the', 'CALO', 'Project', '(', 'A', 'Cognitive', 'Assistant', 'that', 'Learns', 'and', 'Organizes', ')', '.', 'It', 'contains', 'data', 'from', 'about', '150', 'users', ',', 'mostly', 'senior', 'management', 'of', 'Enron', ',', 'organized', 'into', 'folders', '.', 'The', 'of', 'about', '0.5M', 'messages', '.', 'This', 'public', ',', 'and', 'posted', 'to', 'the', 'web', ',', 'by', 'the', 'Federal', 'Energy', 'Regulatory', 'Commission', 'during', 'its', 'investigation', '?', 'The', 'email', 'dataset', 'was', 'later', 'purchased', 'by', 'Leslie', 'Kaelbling', 'at', 'MIT', ',', 'and', 'problems', '.', 'A', 'number', 'of', 'folks', 'at', 'SRI', ',', 'notably', 'Melinda', 'Gervasio', ',', 'worked', 'problems', ',', 'and', 'it', 'is', 'thanks', 'to', 'them', '(', 'not', 'me', ')', 'that', 'the', 'dataset', 'is', 'available', '.', 'The', 'include', 'attachments', ',', 'and', 'been', 'deleted', '\"', 'as', 'part', 'of', 'a', 'redaction', 'effort', 'due', 'to', 'requests', 'from', 'affected', 'employees', '\"', '.', 'Invalid', 'of', 'the', 'form', 'user@enron.com.', ',', \"'\", 'whenever', 'possible', '..', '(', 'i.e.', ',', 'recipient', 'is', 'specified', 'in', 'some', 'parse-able', 'format', 'like', '\"', 'Doe', ',', 'John', '\"', 'or', '\"', 'Mary', 'K.', 'Smith', '\"', ')', 'and', 'to', ',', 'no_address@enron.com', ':', 'koluh_dinno@gmail.com', ';', 'when', 'no', 'recipient', 'was', 'specified', '.', '.', '.', 'I', 'get', 'a', 'each', 'week', ',', 'which', 'I', 'am', 'unable', 'to', 'answer', ',', '$45,000,055', 'mostly', 'that', 'I', 'just', \"don't\", 'know', 'about', '.', 'If', 'you', 'ask', 'me', 'a', 'question', 'and', 'I', \"don't\", 'answer', ',', 'please', \"'\", \"don't\", \"'\", ',', \"don't\", '.', 'mindme', \"'\", 'feel', 'slighted', '.', '.', 'dino', '!', '==', '?', 'hello', ',', 'Mr.', ',']\n"
     ]
    }
   ],
   "source": [
    "name = 'txt3'\n",
    "text = get_text(name)\n",
    "tokenizer = NLP(text)\n",
    "tokenizer.tokenize()\n",
    "tokenizer.sentence_split()\n",
    "sentences = tokenizer.sentences\n",
    "print(text)\n",
    "print(tokenizer.rough_tokens)\n",
    "print(tokenizer.tokens)\n",
    "# for sentence in sentences:\n",
    "#     print([sentence])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66ad2a0fc99eef4a3bf89b375e9b9756c86124817c17e26a015d4a0d647e591d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
